<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Intelligent Perception Lab</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Intelligent Perception Lab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2025 USTC Intelligent Perception Lab </copyright><lastBuildDate>Sun, 15 Aug 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/logo_hua1e91360984d470552124c70967b3097_101197_300x300_fit_lanczos_3.png</url>
      <title>Intelligent Perception Lab</title>
      <link>/</link>
    </image>
    
    <item>
      <title>MMECG</title>
      <link>/datasets/rcg2ecg/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/datasets/rcg2ecg/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/jinbochen0823/RCG2ECG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MMECG&lt;/a&gt; is an open-source dataset of 10 hours of processed mmWave radar data and synchronized ECG measurements collected from 35 participants under four different physiological statuses. This dataset is used in the paper &lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/9919401&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Contactless Electrocardiogram Monitoring With Millimeter Wave Radar&lt;/a&gt;. It can facilitate digital health research based on mmWave radar. (RightNow, we only release 4.55 hours of data. The rest of the data are still under the authorizing process with privacy concern. We will update this page once we finish the authorizing process.) Following, we introduce the composition and implementation details of this dataset.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>HIBER</title>
      <link>/datasets/hiber/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/datasets/hiber/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/Intelligent-Perception-Lab/HIBER?tab=readme-ov-file&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HIBER (Human Indoor Behavior Exclusive RF dataset)&lt;/a&gt; is an open-source mmWave human behavior recognition dataset collected from multiple domains(i.e., various environments, users, occlusions，and actions). It can be used to study human position tracking, human behavior recognition, human pose estimation, and human silhouette generation tasks. The total size of the processed dataset is 400GB, including RF heatmaps, RGB images, 2D/3D human skeletons, bounding boxes, and human silhouette ground truth. Click on the link to learn more details and how to use the dataset!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Activity Perception and Imaging Using Radio Signals</title>
      <link>/projects/humanactivityperception/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/projects/humanactivityperception/</guid>
      <description>&lt;p&gt;In recent years, building radio sensing systems to perceive and understand the activities of humans has drawn increasing attention, mainly due to the non-intrusive and privacy-preserving characteristics of radio signals. Various systems have been designed to track the human&amp;rsquo;s position, actions, and vital signs by analyzing the radio signals reflected off the human body. However, most existing works can only predict rough human information. In this project, we build a multimodal system to enable the fine-grained human activity perception and imaging using radio signals, which consists of three major components: data collection, RF signal processing, and deep learning models. The data collection component collects human activity images from optical cameras and corresponding radio signals from RF devices. The RF signal processing component transforms the radio signals to the signal amplitude heatmaps. The deep learning models can generate human pose keypoints, pose segmentation, or human activity images based on the radio signal heatmaps.&lt;/p&gt;
&lt;!-- &lt;br&gt;
**Related dataset:** 
&lt;br&gt;
[HIBER](https://github.com/Intelligent-Perception-Lab/HIBER): HIBER(Human Indoor Behavior Exclusive RF dataset) is an open-source mmWave human behavior recognition dataset collected from multiple domains(i.e., various environments, users, occlusions，and actions). The total size of the processed dataset is 400GB, including RF heatmaps, RGB images, 2D/3D human skeletons, bounding boxes，and human silhouette ground truth. --&gt;
</description>
    </item>
    
    <item>
      <title>H-WILD</title>
      <link>/datasets/h-wild/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/datasets/h-wild/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/H-WILD/human_held_device_wifi_indoor_localization_dataset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;H-WILD&lt;/a&gt; is a human-held device WiFi localization dataset consisting of 120,000 frames from 10 volunteers across 4 rooms. We collect datasets in four typical indoor scenarios: conference, laboratory, office, and lounge. During data collection, volunteers are instructed to walk freely around the room while holding the transmitter in their hands. They can walk slowly, walk quickly, or stop, just as they normally would do during their daily activities. And we use an Ultra-Wideband (UWB) based localization system with an accuracy of ten of centimeters to collect ground truth location data. Click on the link to learn more details and how to use the dataset!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RF-based Human Sensing</title>
      <link>/projects/rf-basedhumansensing/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/projects/rf-basedhumansensing/</guid>
      <description>&lt;p&gt;In-home human monitoring systems, which could continuously monitor user information such as location and vital sign, have been attractive to provide assistance for personal healthcare, i.e., to provide healthcare professionals with rich information to understand the health conditions of users. For instance, the location information is able to answer the question like “does the person spend too much time somewhere in home?” or “do the couple stay close with each other?” while the vital sign information can be utilized to detect unusual breath and heartbeat, which provides valuable information for medical diagnoses. In this project, we propose a human sensing system with radio signals, MTrack, for in-home healthcare, which is capable of tracking the trajectories of moving persons and vital signs of static persons under the multi-person scenarios.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MCD-Gesture</title>
      <link>/datasets/mcd/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/datasets/mcd/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/leeyadong/cross_domain_gesture_dataset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MCD-Gesture&lt;/a&gt; is a cross-domain gesture dataset consisting of 24050 instances from 25 users, 6 environments, and 5 locations. MCD-Gesture is collected from various domains (i.e. environments, users, and locations), and it can be used to develop mmWave gesture recognition systems and domain-independent machine learning algorithms. Click on the link to learn more details and how to use the dataset!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RadarEyes</title>
      <link>/datasets/radareyes/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/datasets/radareyes/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/ruixv/RadarEyes?tab=readme-ov-file&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RadarEyes&lt;/a&gt; is a point cloud dataset consisting of aligned horizontally placed mmWave radar, vertically placed mmWave radar, LiDAR, and tracking cameras, capturing 120,000 frames of incoherent mmWave radar and 1,200,000 frames of coherent mmWave radar, along with corresponding poses and LiDAR pointcloud. Click on the link to learn more details and how to use the dataset!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Radio Frequency Imaging</title>
      <link>/projects/radio-frequency-imaging/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/projects/radio-frequency-imaging/</guid>
      <description>&lt;p&gt;Radio frequency (RF) imaging technologies aiming to recover shapes of 3-Dimensional objects enable various applications such as smart home, security inspection, and autonomous vehicles. These technologies benefit from the nature of wireless signals, i.e., the wireless signals can work in all-weather and all-day conditions while preventing privacy leakage. However, the existing systems fail to provide fine-grained imaging results, e.g., the result is often composed of several blobs at different positions or the entire object is represented as a single point. In this project, we propose to perform imaging with a large 2D antenna array and wide-band signals.&lt;/p&gt;
&lt;!-- &lt;br&gt;
**Related dataset:**
&lt;br&gt;
[RadarEyes](https://github.com/ruixv/RadarEyes): RadarEyes is a mmWave Pointcloud Dataset. It consists of 1,000,000 frames of mmWave radar, LiDAR, and camera data from 300 indoor scenarios. --&gt;
</description>
    </item>
    
    <item>
      <title>Digital Health</title>
      <link>/projects/digitalhealth/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/projects/digitalhealth/</guid>
      <description>&lt;p&gt;Advances in machine learning and contactless sensors have given rise to digital health. We focus on healthcare in the radio world, leveraging the advances in wireless technology in all aspects of healthcare. 
&lt;br&gt;
Our recent research aims to develop contactless healthcare monitoring schemes based on commercial radio systems to achieve physiological information monitoring and health-critical human behaviors sensing under clinical and in-home environments. 
&lt;br&gt;
&lt;strong&gt;Physiological information monitoring:&lt;/strong&gt;  We not only precisely measure the respiration and heartbeat rate, but also look deeper into the human body, e.g., monitoring electrocardiogram and blood pressure contactlessly. The proposed hybrid pipeline of signal processing and deep learning framework first extracts human micro-activity measurements from RF signal and then predicts the ECG and blood pressure with an interpretable neural networks that incorporate domain knowledge of RF signal and physiological models.
&lt;br&gt;
&lt;strong&gt;Health-critical human behaviors sensing:&lt;/strong&gt; Beyond the physiological information, we also exploit RF signal to sense health-critical human behaviors such as fall. Our RF-based fall detection system utilizes spatio-temporal convolutional neural networks to aggregate information across space and time and extract the corresponding complex spatio-temporal patterns. We address the main challenge in practice fall detection, including dealing with complex falls and fast non-fall movements, generalization to new environments and detecting falls in the presence of other motion.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wireless Sensing with Reconfigurable Intelligent Surface</title>
      <link>/projects/wireless-sensing-with-reconfigurable-intelligent-surface/</link>
      <pubDate>Sat, 07 Aug 2021 19:30:35 +0800</pubDate>
      <guid>/projects/wireless-sensing-with-reconfigurable-intelligent-surface/</guid>
      <description>&lt;p&gt;Indoor positioning is of great significance for common applications, such as elderly health, intrusion detection. However, insufficient distance resolution caused by the narrow-band characterization of WiFi signal makes it difficult to achieve accurate positioning. The emergence of Reconfigurable Intelligent Surface (RIS) makes it possible to solve this problem. The RIS can be regarded as a phase shifter, and focus the incident waves on certain location. We currently use RIS to improve the accuracy of positioning with WiFi signals and solve the near-far effect in multi-person scenarios.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fashion Recommendation and Synthesis</title>
      <link>/project/fashion/</link>
      <pubDate>Sun, 15 Aug 2021 00:00:00 +0000</pubDate>
      <guid>/project/fashion/</guid>
      <description>&lt;p&gt;Fashion plays an important role in everyone&amp;rsquo;s daily life. In this project, we focus on fashion outfit recommendation and synthesis tasks which have wide applications in fashion oriented social networks, online shopping and smart home. Outfit recommendation is the task of predicting whether a set of fashion items that constitute an outfit are well-matched and fashion synthesis is to generate new fashion items considering such compatibilities. We further study those problems under the consideration of personalization. In the collaboration with intelligent devices, the system can be deployed in smart home to improve the quality of people&amp;rsquo;s life. With the personalized fashion recommendation technique, we can help people make the most of their fashion items, improve their shopping experiences and recommend appropriate dress for important occasions. With the fashion synthesis technique, we can generate new compatible items for people, give insights and reduce anxiety for making choices for their next shopping.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Activity Perception and Imaging Using Radio Signals</title>
      <link>/project/rfperception/</link>
      <pubDate>Sat, 07 Aug 2021 19:45:56 +0800</pubDate>
      <guid>/project/rfperception/</guid>
      <description>&lt;p&gt;In recent years, building radio sensing systems to perceive and understand the activities of humans has drawn increasing attention, mainly due to the non-intrusive and privacy-preserving characteristics of radio signals. Various systems have been designed to track the human&amp;rsquo;s position, actions, and vital signs by analyzing the radio signals reflected off the human body. However, most existing works can only predict rough human information. In this project, we build a multimodal system to enable the fine-grained human activity perception and imaging using radio signals, which consists of three major components: data collection, RF signal processing, and deep learning models. The data collection component collects human activity images from optical cameras and corresponding radio signals from RF devices. The RF signal processing component transforms the radio signals to the signal amplitude heatmaps. The deep learning models can generate human pose keypoints, pose segmentation, or human activity images based on the radio signal heatmaps. Furthermore, to train and test our proposed system, we make a cross-modal dataset, i.e., RFVisionData.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Test</title>
      <link>/project/test/</link>
      <pubDate>Sat, 07 Aug 2021 19:45:56 +0800</pubDate>
      <guid>/project/test/</guid>
      <description>&lt;p&gt;We propose a human sensing system with radio signals, MTrack, for in-home healthcare, which is capable of tracking the trajectories of moving persons and vital signs of static persons under the multi-person scenarios. To achieve this, we implement a multi-antenna wideband system that can provide high-resolution angle of arrival (AoA) and time of flight (ToF). A 2D beamformer is utilized to transform the raw radio signals into the AoA-ToF domain. To track the trajectories of moving persons, we leverage the movement of persons to cancel static multipaths and propose a path selection algorithm to estimate the locations of human and suppress the interferences from dynamic multipaths. To track the vital signs of static persons, we utilize the breath of static persons to eliminate static multipaths and propose a correlation-based algorithm to eliminate dynamic multipaths. Extensive experiments show that the proposed MTrack system is capable of tracking multiple moving persons with sub-decimeter level accuracy, and can estimate the breath and heartbeat rate of static persons with median accuracy of 99.8% and 98.46%, respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/admin/config.yml</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/all-publications/allpub/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/all-publications/allpub/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/allpubs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/allpubs/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
